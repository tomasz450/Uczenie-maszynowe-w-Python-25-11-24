{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Równanie normalne\n",
    "\n",
    "Równanie normalne to technika, która pozwala na bezpośrednie obliczenie współczynników regresji w modelu liniowym. W przypadku regresji prostej, równanie normalne można zapisać jako:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = (X'X)^{-1}X'y\n",
    "$$\n",
    "\n",
    "gdzie:\n",
    "\n",
    "- $ \\hat{\\beta} $ to wektor estymowanych współczynników regresji,\n",
    "- $ X $ to macierz zmiennych niezależnych (z dodaną kolumną jedynek dla wyrazu wolnego),\n",
    "- $ y $ to wektor zmiennej zależnej.\n",
    "\n",
    "Metoda ta jest szczególnie efektywna, gdy liczba obserwacji jest niewielka, ponieważ wymaga obliczenia macierzy odwrotnej, co może być kosztowne obliczeniowo dla dużych zbiorów danych. Równanie normalne zapewnia, że wartości współczynników są takie, które minimalizują sumę kwadratów reszt (różnic między wartościami obserwowanymi a przewidywanymi) [2][3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lata pracy: [1 2 3 4 5 6]\n",
      "Wynagrodzenie: [3000 3250 3500 3750 4000 4250]\n",
      "Liczba próbek: 6\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([1, 2, 3, 4, 5, 6])\n",
    "Y = np.array([3000, 3250, 3500, 3750, 4000, 4250])\n",
    "m = len(X1)\n",
    "\n",
    "print(f'Lata pracy: {X1}')\n",
    "print(f'Wynagrodzenie: {Y}')\n",
    "print(f'Liczba próbek: {m}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]]\n",
      "(6, 1)\n"
     ]
    }
   ],
   "source": [
    "X1 = X1.reshape(m, 1)\n",
    "print(X1)\n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "(6, 1)\n"
     ]
    }
   ],
   "source": [
    "bias = np.ones((m, 1))\n",
    "print(bias)\n",
    "print(bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 2.]\n",
      " [1. 3.]\n",
      " [1. 4.]\n",
      " [1. 5.]\n",
      " [1. 6.]]\n",
      "(6, 2)\n"
     ]
    }
   ],
   "source": [
    "X = np.append(bias, X1, axis=1)\n",
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name='2'></a> Równanie normalne - operacje macierzowe\n",
    "\n",
    "Regresja liniowa w $R^2$:\n",
    "$$Y = w_0 + w_1X_1$$\n",
    "$$Y = W^TX$$\n",
    "gdzie: $$W= \\left[\\begin{matrix}w_0\\\\w_1\\end{matrix}\\right]$$ $$ X= \\left[\\begin{matrix}1\\\\X_1\\end{matrix}\\right] $$ stąd $$ W^T= \\left[\\begin{matrix}w_0&w_1\\end{matrix}\\right] $$    \n",
    "$$Y = W^TX = \\left[\\begin{matrix}w_0&w_1\\end{matrix}\\right] \\cdot  \\left[\\begin{matrix}1\\\\X_1\\end{matrix}\\right] = w_0 + w_1X_1$$\n",
    "\n",
    "Równanie normalne - równanie pozwalające obliczyć minimum funkcji straty (o ile istnieje)\n",
    "$$W = (X^TX)^{-1}(X^TY)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6., 21.],\n",
       "       [21., 91.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X.T, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.86666667, -0.2       ],\n",
       "       [-0.2       ,  0.05714286]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = np.linalg.inv(np.dot(X.T, X))\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21750., 80500.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = np.dot(X.T, Y)\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2750.,  250.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(L, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Końcowa postać modelu$$Y = 2750 + 250X_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "01_linear_regression_normal_equation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
